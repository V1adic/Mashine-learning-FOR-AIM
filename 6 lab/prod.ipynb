{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vnori\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 16000 examples [00:00, 235368.94 examples/s]\n",
      "Generating test split: 2000 examples [00:00, 133370.56 examples/s]\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vnori\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i didnt feel humiliated']\n",
      "['able' 'absolutely' 'accepted' 'aching' 'actually' 'admit' 'afraid'\n",
      " 'agitated' 'ago' 'almost' 'alone' 'already' 'also' 'always' 'amazed'\n",
      " 'amazing' 'amp' 'angry' 'annoyed' 'another' 'anxious' 'anymore' 'anyone'\n",
      " 'anything' 'apprehensive' 'around' 'ashamed' 'ask' 'asked' 'assured'\n",
      " 'away' 'awful' 'awkward' 'baby' 'back' 'bad' 'beaten' 'beautiful'\n",
      " 'become' 'bed' 'began' 'believe' 'beloved' 'best' 'better' 'big' 'bit'\n",
      " 'blank' 'blessed' 'blog' 'body' 'book' 'books' 'bothered' 'brave'\n",
      " 'burdened' 'call' 'calm' 'came' 'cannot' 'cant' 'care' 'caring' 'cause'\n",
      " 'certain' 'change' 'child' 'children' 'class' 'close' 'cold' 'come'\n",
      " 'comes' 'comfortable' 'coming' 'completely' 'confident' 'confused'\n",
      " 'content' 'control' 'convinced' 'cool' 'could' 'couldnt' 'cranky'\n",
      " 'creative' 'curious' 'cute' 'dangerous' 'day' 'days' 'decided'\n",
      " 'depressed' 'determined' 'devastated' 'didnt' 'different' 'dirty'\n",
      " 'disappointed' 'discouraged' 'divine' 'doesnt' 'done' 'dont' 'dull' 'eat'\n",
      " 'either' 'else' 'embarrassed' 'emotional' 'empty' 'end' 'energy' 'enjoy'\n",
      " 'enough' 'especially' 'even' 'ever' 'every' 'everyone' 'everything'\n",
      " 'excited' 'exhausted' 'experience' 'extremely' 'eyes' 'face' 'fact'\n",
      " 'family' 'far' 'feel' 'feeling' 'feelings' 'feels' 'felt' 'finally'\n",
      " 'find' 'fine' 'first' 'food' 'found' 'free' 'friend' 'friends'\n",
      " 'frustrated' 'fucked' 'full' 'fun' 'funny' 'future' 'generous' 'get'\n",
      " 'getting' 'girl' 'give' 'giving' 'glad' 'gloomy' 'go' 'god' 'going'\n",
      " 'gone' 'good' 'gorgeous' 'got' 'great' 'greedy' 'groggy' 'guess' 'guilty'\n",
      " 'guy' 'hair' 'hand' 'happen' 'happened' 'happy' 'hard' 'hate' 'hated'\n",
      " 'havent' 'head' 'hear' 'heart' 'help' 'helpless' 'hes' 'home' 'homesick'\n",
      " 'honestly' 'honored' 'hope' 'hopeful' 'hopeless' 'horrible' 'hot' 'hours'\n",
      " 'house' 'however' 'href' 'http' 'hurt' 'husband' 'id' 'idea' 'ill' 'im'\n",
      " 'important' 'impressed' 'incredibly' 'innocent' 'insecure' 'inside'\n",
      " 'inspired' 'instead' 'insulted' 'irritable' 'irritated' 'isolated' 'ive'\n",
      " 'jealous' 'job' 'joyful' 'keep' 'kids' 'kind' 'kinda' 'knew' 'know'\n",
      " 'knowing' 'last' 'lately' 'least' 'leave' 'left' 'less' 'let' 'lethargic'\n",
      " 'life' 'like' 'liked' 'little' 'live' 'living' 'lonely' 'long' 'longer'\n",
      " 'look' 'looking' 'lost' 'lot' 'love' 'loved' 'lovely' 'loving' 'low'\n",
      " 'lucky' 'mad' 'made' 'make' 'makes' 'making' 'man' 'many' 'matter' 'may'\n",
      " 'maybe' 'mean' 'melancholy' 'might' 'mind' 'mine' 'miserable' 'miss'\n",
      " 'missed' 'mom' 'moment' 'money' 'months' 'morning' 'mother' 'move' 'much'\n",
      " 'music' 'must' 'need' 'needed' 'nervous' 'never' 'new' 'next' 'nice'\n",
      " 'night' 'nothing' 'numb' 'offended' 'often' 'ok' 'old' 'one' 'open'\n",
      " 'optimistic' 'others' 'overwhelmed' 'pain' 'paranoid' 'parents' 'part'\n",
      " 'particularly' 'passionate' 'past' 'pathetic' 'people' 'perfect' 'person'\n",
      " 'pissed' 'place' 'pleasant' 'point' 'popular' 'positive' 'post'\n",
      " 'precious' 'pressured' 'pretty' 'probably' 'proud' 'punished' 'put'\n",
      " 'quite' 'rather' 'read' 'reading' 'ready' 'real' 'really' 'reason'\n",
      " 'rejected' 'relaxed' 'reluctant' 'remember' 'resentful' 'respected'\n",
      " 'rest' 'rich' 'right' 'room' 'rude' 'run' 'running' 'rushed' 'sad' 'safe'\n",
      " 'said' 'satisfied' 'say' 'saying' 'scared' 'school' 'see' 'seeing' 'seem'\n",
      " 'seems' 'self' 'selfish' 'sense' 'set' 'shaken' 'share' 'shitty' 'show'\n",
      " 'sick' 'side' 'simply' 'since' 'sit' 'sitting' 'situation' 'sleep'\n",
      " 'slightly' 'small' 'somehow' 'someone' 'something' 'sometimes' 'somewhat'\n",
      " 'soon' 'sorry' 'sort' 'special' 'spent' 'start' 'started' 'starting'\n",
      " 'stay' 'still' 'stop' 'story' 'strange' 'stressed' 'strong' 'stuff'\n",
      " 'stupid' 'successful' 'super' 'support' 'supporting' 'sure' 'surprised'\n",
      " 'sweet' 'sympathetic' 'take' 'taking' 'talented' 'talk' 'talking' 'tell'\n",
      " 'terrible' 'terrified' 'thankful' 'thats' 'theres' 'thing' 'things'\n",
      " 'think' 'thinking' 'though' 'thought' 'thoughts' 'time' 'times' 'tired'\n",
      " 'today' 'together' 'told' 'tonight' 'took' 'tortured' 'totally' 'towards'\n",
      " 'truly' 'try' 'trying' 'turn' 'two' 'ugly' 'uncertain' 'uncomfortable'\n",
      " 'understand' 'unhappy' 'unsure' 'unwelcome' 'us' 'use' 'used' 'useful'\n",
      " 'useless' 'usually' 'valuable' 'valued' 'violent' 'vulnerable' 'wake'\n",
      " 'walk' 'want' 'wanted' 'wanting' 'wasnt' 'watch' 'watching' 'way' 'ways'\n",
      " 'wear' 'week' 'weeks' 'weird' 'well' 'went' 'whether' 'whole' 'wish'\n",
      " 'without' 'woke' 'woman' 'women' 'wonder' 'wonderful' 'wont' 'words'\n",
      " 'work' 'working' 'world' 'would' 'write' 'writing' 'wrong' 'wronged'\n",
      " 'year' 'years' 'yet' 'youre']\n",
      "2.52371815232768\n",
      "0.545\n",
      "ADA\n",
      "{'algorithm': 'SAMME.R', 'estimator__ccp_alpha': 0.0, 'estimator__class_weight': None, 'estimator__criterion': 'gini', 'estimator__max_depth': 6, 'estimator__max_features': None, 'estimator__max_leaf_nodes': None, 'estimator__min_impurity_decrease': 0.0, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 2, 'estimator__min_weight_fraction_leaf': 0.0, 'estimator__monotonic_cst': None, 'estimator__random_state': 42, 'estimator__splitter': 'best', 'estimator': DecisionTreeClassifier(max_depth=6, random_state=42), 'learning_rate': 1.0, 'n_estimators': 100, 'random_state': None}\n",
      "blending -> 0.405\n",
      "0.362\n",
      "stacking -> 0.413\n",
      "0.368\n",
      "0.6485\n",
      "GBC\n",
      "{'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 6, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 42, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "blending -> 0.405\n",
      "0.362\n",
      "stacking -> 0.413\n",
      "0.368\n",
      "Параметры моделей выбрались идентичным образом!!!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "def make_blending_prediction(basic_clfs, final_clf, data):\n",
    "    y0 = []\n",
    "    for c in basic_clfs:\n",
    "        y0.append(c.predict(data))\n",
    "    y0_t = np.array(y0).transpose()\n",
    "    return final_clf.predict(y0_t)\n",
    "\n",
    "def make_stacking_prediction(basic_clfs, final_clf, data):\n",
    "    y0 = []\n",
    "    for c in basic_clfs:\n",
    "        y0.append(c.predict(data))\n",
    "    y0_t = np.array(y0).transpose()\n",
    "    return final_clf.predict(y0_t)\n",
    "\n",
    "\n",
    "dataset = load_dataset('json', data_files={'train': 'Data/train.jsonl','test':'Data/validation.jsonl'})\n",
    "nltk.download('stopwords')\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=500, min_df=4, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X_train_vec = vectorizer.fit_transform(dataset['train']['text'])\n",
    "\n",
    "print(dataset['train']['text'][:1])\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "print(vocabulary)\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "X_train_idf = tfidf.fit_transform(X_train_vec)\n",
    "\n",
    "X_test_vec = vectorizer.transform(dataset['test']['text'])\n",
    "X_test_idf = tfidf.transform(X_test_vec)\n",
    "print(X_test_idf[:1].toarray().sum())\n",
    "\n",
    "X_train = X_train_idf.toarray()\n",
    "X_test = X_test_idf.toarray()\n",
    "X_train, X_test, y_train, y_test = X_train, X_test, dataset['train']['label'], dataset['test']['label']\n",
    "\n",
    "# Глава 2, обучение на объектах, неверно классифицированных на предыдущем шаге\n",
    "\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, max_depth = 6, random_state=42)\n",
    "\n",
    "filename = \"./models/AdaBoost_100_6.pickle\"\n",
    "model = pickle.load(open(filename, \"rb\"))\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"ADA\")\n",
    "print(model.get_params())\n",
    "\n",
    "X_train_0, X_train_1, y_train_0, y_train_1 = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "# Blending\n",
    "\n",
    "N = 10\n",
    "y_pred_1 = []\n",
    "crf = []\n",
    "for n in range(1,N+1):\n",
    "    crf.append(RandomForestClassifier(n_estimators = 2,max_depth=2, random_state=n))\n",
    "    crf[-1].fit(X_train_0,y_train_0)\n",
    "    y_pred_1.append(crf[-1].predict(X_train_1).reshape(len(X_train_1),1))\n",
    "    y_pred_1t = np.array(y_pred_1).transpose()[0]\n",
    "\n",
    "y_pred_1t = np.array(y_pred_1).transpose()[0]\n",
    "clf_final = RandomForestClassifier(n_estimators = 10,max_depth=6, random_state=42)\n",
    "clf_final.fit(y_pred_1t,y_train_1)\n",
    "\n",
    "y_test_pred = make_blending_prediction(crf,clf_final, X_test)\n",
    "print(f\"blending -> {metrics.accuracy_score(y_test, y_test_pred)}\")\n",
    "print(metrics.accuracy_score(y_test, crf[0].predict(X_test)))\n",
    "\n",
    "N = 10\n",
    "y_pred_1 = []\n",
    "crf_stack = []\n",
    "kf = KFold(n_splits=N, random_state=None, shuffle=False)\n",
    "\n",
    "x_test_2 = []\n",
    "y_test_2 = []\n",
    "\n",
    "pre_prediction = np.zeros((len(X_train), N))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "    X_train_0, X_test_1 = np.array(X_train)[train_index], np.array(X_train)[test_index]\n",
    "    y_train_0, y_test_1 = np.array(y_train)[train_index], np.array(y_train)[test_index]\n",
    "    \n",
    "    crf_stack.append(RandomForestClassifier(n_estimators = 2,max_depth=2, random_state=i))\n",
    "    crf_stack[-1].fit(X_train_0,y_train_0)\n",
    "    pre_prediction[test_index,i]=crf_stack[-1].predict(X_test_1)\n",
    "\n",
    "clf_stack_final = RandomForestClassifier(n_estimators = 10,max_depth=6, random_state=42)\n",
    "clf_stack_final.fit(pre_prediction,y_train)\n",
    "\n",
    "y_test_pred = make_stacking_prediction(crf_stack,clf_stack_final, X_test)\n",
    "print(f\"stacking -> {metrics.accuracy_score(y_test, y_test_pred)}\")\n",
    "print(metrics.accuracy_score(y_test, crf_stack[0].predict(X_test)))\n",
    "\n",
    "# Глава 3, обучение в направленном\n",
    "\n",
    "filename = \"./models/GBC_100_6.pickle\"\n",
    "model = pickle.load(open(filename, \"rb\"))\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"GBC\")\n",
    "print(model.get_params())\n",
    "\n",
    "X_train_0, X_train_1, y_train_0, y_train_1 = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "# Blending\n",
    "N = 10\n",
    "y_pred_1 = []\n",
    "crf = []\n",
    "for n in range(1,N+1):\n",
    "    crf.append(RandomForestClassifier(n_estimators = 2,max_depth=2, random_state=n))\n",
    "    crf[-1].fit(X_train_0,y_train_0)\n",
    "    y_pred_1.append(crf[-1].predict(X_train_1).reshape(len(X_train_1),1))\n",
    "    y_pred_1t = np.array(y_pred_1).transpose()[0]\n",
    "\n",
    "y_pred_1t = np.array(y_pred_1).transpose()[0]\n",
    "\n",
    "clf_final = RandomForestClassifier(n_estimators = 10,max_depth=6, random_state=42)\n",
    "clf_final.fit(y_pred_1t,y_train_1)\n",
    "\n",
    "y_test_pred = make_blending_prediction(crf,clf_final, X_test)\n",
    "print(f\"blending -> {metrics.accuracy_score(y_test, y_test_pred)}\")\n",
    "print(metrics.accuracy_score(y_test, crf[0].predict(X_test)))\n",
    "\n",
    "N = 10\n",
    "y_pred_1 = []\n",
    "crf_stack = []\n",
    "kf = KFold(n_splits=N, random_state=None, shuffle=False)\n",
    "\n",
    "x_test_2 = []\n",
    "y_test_2 = []\n",
    "\n",
    "pre_prediction = np.zeros((len(X_train), N))\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "    X_train_0, X_test_1 = np.array(X_train)[train_index], np.array(X_train)[test_index]\n",
    "    y_train_0, y_test_1 = np.array(y_train)[train_index], np.array(y_train)[test_index]\n",
    "    \n",
    "    crf_stack.append(RandomForestClassifier(n_estimators = 2,max_depth=2, random_state=i))\n",
    "    crf_stack[-1].fit(X_train_0,y_train_0)\n",
    "    pre_prediction[test_index,i]=crf_stack[-1].predict(X_test_1)\n",
    "\n",
    "clf_stack_final = RandomForestClassifier(n_estimators = 10,max_depth=6, random_state=42)\n",
    "clf_stack_final.fit(pre_prediction,y_train)\n",
    "\n",
    "y_test_pred = make_stacking_prediction(crf_stack,clf_stack_final, X_test)\n",
    "print(f\"stacking -> {metrics.accuracy_score(y_test, y_test_pred)}\")\n",
    "print(metrics.accuracy_score(y_test, crf_stack[0].predict(X_test)))\n",
    "\n",
    "print(\"Параметры моделей выбрались идентичным образом!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
